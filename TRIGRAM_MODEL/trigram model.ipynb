{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4bf573-0b9f-406c-9506-c6298c6dbd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Trigram Language Model - Training Script\n",
      "======================================================================\n",
      "\n",
      "Available books:\n",
      "  alice: Alice's Adventures in Wonderland\n",
      "  pride: Pride and Prejudice\n",
      "  frankenstein: Frankenstein\n",
      "  tale: A Tale of Two Cities\n",
      "\n",
      "Training on: Pride and Prejudice\n",
      "======================================================================\n",
      "\n",
      "Downloading 'Pride and Prejudice'...\n",
      " Successfully downloaded 'Pride and Prejudice' (743383 characters)\n",
      "Cleaned text: 743241 characters\n",
      "\n",
      "Training trigram model...\n",
      "Training completed in 0.71 seconds\n",
      "\n",
      "Model Statistics:\n",
      "  Vocabulary size: 4,170\n",
      "  Unique contexts: 51,717\n",
      "  Total trigrams: 157,275\n",
      "  Avg next words per context: 2.01\n",
      "\n",
      "======================================================================\n",
      "Generating 5 sample texts:\n",
      "======================================================================\n",
      "\n",
      "Sample 1:\n",
      "Jane ran to her partner to oblige him to visit her the information herself and her expectations of felicity to have his errors made public might ruin him in.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Sample 2:\n",
      "I can from my poor mother is tolerably well i suppose who have heart enough to make another choice?\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Sample 3:\n",
      "Gardiner began to fear they are!\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Sample 4:\n",
      "In his power and steadfastly was she repeating why is not it would be attended to the saloon miss bingley seated near him was watching the occasional exclamation of lord how tired i am particularly attached to me very faint indeed.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Sample 5:\n",
      "On the very day of lydias example she became at all.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " All done\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Tuple\n",
    "import bisect\n",
    "\n",
    "class TrigramModel:\n",
    "    def __init__(self):\n",
    "        self.trigram_counts = defaultdict(Counter)\n",
    "        \n",
    "        self.context_totals = defaultdict(int)\n",
    "        \n",
    "        # Special tokens\n",
    "        self.START = \"<START>\"\n",
    "        self.END = \"<END>\"\n",
    "        self.UNK = \"<UNK>\"\n",
    "        \n",
    "        self.vocab = set()\n",
    "        self.min_word_freq = 2  \n",
    "        self.word_freq = Counter()\n",
    "    \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Replace newlines and tabs with spaces\n",
    "        text = re.sub(r'[\\n\\t\\r]+', ' ', text)\n",
    "        \n",
    "        text = re.sub(r'[^a-z\\s\\.\\!\\?\\,\\;\\:\\'\\-]', '', text)\n",
    "        \n",
    "        # Normalize multiple spaces\n",
    "        text = re.sub(r'\\s+', ' ', text)\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        tokens = re.findall(r'\\w+(?:\\'\\w+)?|[.!?]', text)\n",
    "        return tokens\n",
    "    \n",
    "    def _pad_text(self, tokens: List[str]) -> List[str]:\n",
    "        padded = []\n",
    "        \n",
    "        # Add two start tokens\n",
    "        padded.extend([self.START, self.START])\n",
    "        \n",
    "        for token in tokens:\n",
    "            padded.append(token)\n",
    "            if token in {'.', '!', '?'}:\n",
    "                padded.append(self.END)\n",
    "                padded.extend([self.START, self.START])\n",
    "        \n",
    "        if padded[-1] != self.END:\n",
    "            padded.append(self.END)\n",
    "        \n",
    "        return padded\n",
    "    \n",
    "    def fit(self, text: str):\n",
    "        # Step 1: Clean the text\n",
    "        cleaned = self._clean_text(text)\n",
    "        \n",
    "        # Step 2: Tokenize\n",
    "        tokens = self._tokenize(cleaned)\n",
    "        \n",
    "        # Step 3: Count word frequencies for vocabulary\n",
    "        self.word_freq.update(tokens)\n",
    "        \n",
    "        # Build vocabulary \n",
    "        self.vocab = {word for word, count in self.word_freq.items() \n",
    "                      if count >= self.min_word_freq}\n",
    "        self.vocab.update([self.START, self.END])\n",
    "        \n",
    "        # Replace rare words with <UNK>\n",
    "        tokens = [word if word in self.vocab else self.UNK for word in tokens]\n",
    "        \n",
    "        # Step 4: Pad with start/end tokens\n",
    "        padded = self._pad_text(tokens)\n",
    "        \n",
    "        for i in range(len(padded) - 2):\n",
    "            w1, w2, w3 = padded[i], padded[i+1], padded[i+2]\n",
    "            context = (w1, w2)\n",
    "            \n",
    "            self.trigram_counts[context][w3] += 1\n",
    "            self.context_totals[context] += 1\n",
    "    \n",
    "    def _get_next_word(self, context: Tuple[str, str]) -> str:\n",
    "        if context not in self.trigram_counts:\n",
    "            return random.choice(list(self.vocab))\n",
    "        \n",
    "        next_words = self.trigram_counts[context]\n",
    "        total = self.context_totals[context]\n",
    "      \n",
    "        words = list(next_words.keys())\n",
    "        cumulative = []\n",
    "        cumsum = 0\n",
    "        \n",
    "        for word in words:\n",
    "            cumsum += next_words[word] / total\n",
    "            cumulative.append(cumsum)\n",
    "        \n",
    "        rand_val = random.random()\n",
    "        idx = bisect.bisect_left(cumulative, rand_val)\n",
    "        \n",
    "        if idx >= len(words):\n",
    "            idx = len(words) - 1\n",
    "            \n",
    "        return words[idx]\n",
    "    \n",
    "    def generate(self, max_length: int = 50, seed: int = None) -> str:\n",
    "        if seed is not None:\n",
    "            random.seed(seed)\n",
    "        \n",
    "        # Check if model is trained\n",
    "        if not self.trigram_counts:\n",
    "            return \"Model not trained. Please call fit() first.\"\n",
    "        \n",
    "        # Start with two START tokens\n",
    "        generated = [self.START, self.START]\n",
    "        \n",
    "        while len(generated) < max_length + 2:\n",
    "            context = (generated[-2], generated[-1])\n",
    "            next_word = self._get_next_word(context)\n",
    "            \n",
    "            generated.append(next_word)\n",
    "            \n",
    "            # Stop at END token\n",
    "            if next_word == self.END:\n",
    "                break\n",
    "        \n",
    "        result = [word for word in generated[2:] \n",
    "                  if word not in {self.START, self.END, self.UNK}]\n",
    "        \n",
    "        # Join words and clean up spacing around punctuation\n",
    "        text = ' '.join(result)\n",
    "        text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)\n",
    "        \n",
    "        if text:\n",
    "            text = text[0].upper() + text[1:]\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def get_model_stats(self) -> Dict:\n",
    "        \"\"\"Returns statistics about the trained model.\"\"\"\n",
    "        return {\n",
    "            'unique_contexts': len(self.trigram_counts),\n",
    "            'vocabulary_size': len(self.vocab),\n",
    "            'total_trigrams': sum(self.context_totals.values()),\n",
    "            'avg_next_words_per_context': \n",
    "                sum(len(words) for words in self.trigram_counts.values()) / \n",
    "                max(len(self.trigram_counts), 1)\n",
    "        }\n",
    "\n",
    "\n",
    "import requests\n",
    "import time\n",
    "BOOKS = {\n",
    "    'alice': {\n",
    "        'url': 'https://www.gutenberg.org/files/11/11-0.txt',\n",
    "        'title': \"Alice's Adventures in Wonderland\"\n",
    "    },\n",
    "    'pride': {\n",
    "        'url': 'https://www.gutenberg.org/files/1342/1342-0.txt',\n",
    "        'title': 'Pride and Prejudice'\n",
    "    },\n",
    "    'frankenstein': {\n",
    "        'url': 'https://www.gutenberg.org/files/84/84-0.txt',\n",
    "        'title': 'Frankenstein'\n",
    "    },\n",
    "    'tale': {\n",
    "        'url': 'https://www.gutenberg.org/files/98/98-0.txt',\n",
    "        'title': 'A Tale of Two Cities'\n",
    "    }\n",
    "}\n",
    "\n",
    "def download_book(url: str, title: str) -> str:\n",
    "    print(f\"Downloading '{title}'...\")\n",
    "    try:\n",
    "        response = requests.get(url, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        print(f\" Successfully downloaded '{title}' ({len(response.text)} characters)\")\n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error downloading '{title}': {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def clean_gutenberg_text(text: str) -> str: \n",
    "    start_markers = [\n",
    "        \"*** START OF THIS PROJECT GUTENBERG\",\n",
    "        \"*** START OF THE PROJECT GUTENBERG\",\n",
    "        \"*END*THE SMALL PRINT\"\n",
    "    ]\n",
    "    \n",
    "    start_idx = 0\n",
    "    for marker in start_markers:\n",
    "        idx = text.find(marker)\n",
    "        if idx != -1:\n",
    "            # Skip past the marker line\n",
    "            start_idx = text.find('\\n', idx) + 1\n",
    "            break\n",
    "    \n",
    "    # Find the end of the content\n",
    "    end_markers = [\n",
    "        \"*** END OF THIS PROJECT GUTENBERG\",\n",
    "        \"*** END OF THE PROJECT GUTENBERG\",\n",
    "        \"End of Project Gutenberg\",\n",
    "        \"End of the Project Gutenberg\"\n",
    "    ]\n",
    "    \n",
    "    end_idx = len(text)\n",
    "    for marker in end_markers:\n",
    "        idx = text.find(marker)\n",
    "        if idx != -1:\n",
    "            end_idx = idx\n",
    "            break\n",
    "    \n",
    "    # Extract the main content\n",
    "    content = text[start_idx:end_idx]\n",
    "    \n",
    "    return content.strip()\n",
    "\n",
    "def train_model(book_key: str = 'pride') -> TrigramModel:\n",
    "    if book_key not in BOOKS:\n",
    "        raise ValueError(f\"Unknown book key: {book_key}. Choose from {list(BOOKS.keys())}\")\n",
    "    \n",
    "    book_info = BOOKS[book_key]\n",
    "    \n",
    "    # Download the book\n",
    "    raw_text = download_book(book_info['url'], book_info['title'])\n",
    "    \n",
    "    if not raw_text:\n",
    "        raise RuntimeError(\"Failed to download book\")\n",
    "    \n",
    "    # Clean Gutenberg metadata\n",
    "    text = clean_gutenberg_text(raw_text)\n",
    "    print(f\"Cleaned text: {len(text)} characters\")\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"\\nTraining trigram model...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model = TrigramModel()\n",
    "    model.fit(text)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Display model statistics\n",
    "    stats = model.get_model_stats()\n",
    "    print(\"\\nModel Statistics:\")\n",
    "    print(f\"  Vocabulary size: {stats['vocabulary_size']:,}\")\n",
    "    print(f\"  Unique contexts: {stats['unique_contexts']:,}\")\n",
    "    print(f\"  Total trigrams: {stats['total_trigrams']:,}\")\n",
    "    print(f\"  Avg next words per context: {stats['avg_next_words_per_context']:.2f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_samples(model: TrigramModel, num_samples: int = 5, max_length: int = 50):\n",
    "  \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Generating {num_samples} sample texts:\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        text = model.generate(max_length=max_length, seed=i)\n",
    "        print(f\"Sample {i+1}:\")\n",
    "        print(f\"{text}\\n\")\n",
    "        print(f\"{'-'*70}\\n\")\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*70)\n",
    "    print(\"Trigram Language Model - Training Script\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nAvailable books:\")\n",
    "    for key, info in BOOKS.items():\n",
    "        print(f\"  {key}: {info['title']}\")\n",
    "    \n",
    "    book_choice = 'pride' #'alice'  # Change to 'pride'#, 'frankenstein', or 'tale'\n",
    "    \n",
    "    print(f\"\\nTraining on: {BOOKS[book_choice]['title']}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Train the model\n",
    "    model = train_model(book_choice)\n",
    "    \n",
    "    # Generate sample texts\n",
    "    generate_samples(model, num_samples=5, max_length=50)\n",
    "    \n",
    "    print(\"\\n All done\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf088ab7-e908-4ed6-b2d5-b45edf599ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70224cda-abfc-4400-b73e-aea2656a6e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
